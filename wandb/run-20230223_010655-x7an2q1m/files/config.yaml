wandb_version: 1

_action_groups:
  desc: null
  value:
  - <argparse._ArgumentGroup object at 0x7fac3b6cf4d0>
  - <argparse._ArgumentGroup object at 0x7fac3c462810>
  - <argparse._ArgumentGroup object at 0x7fac3bb5c8d0>
  - <argparse._ArgumentGroup object at 0x7fac3b590350>
  - <argparse._ArgumentGroup object at 0x7fac3ade4f50>
  - <argparse._ArgumentGroup object at 0x7fac3adf7ad0>
_actions:
  desc: null
  value:
  - _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None,
    default='==SUPPRESS==', type=None, choices=None, help='show this help message
    and exit', metavar=None)
  - _StoreTrueAction(option_strings=['--silent'], dest='silent', nargs=0, const=True,
    default=False, type=None, choices=None, help='Whether to print progress bars.',
    metavar=None)
  - _StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True,
    default=False, type=None, choices=None, help='Whether to run in debug mode with
    only 200 samples.', metavar=None)
  - _StoreAction(option_strings=['--data_parallel'], dest='data_parallel', nargs=None,
    const=None, default=True, type=<class 'bool'>, choices=None, help='Whether to
    distributed the candidate generation process.', metavar=None)
  - _StoreTrueAction(option_strings=['--no_cuda'], dest='no_cuda', nargs=0, const=True,
    default=False, type=None, choices=None, help='Whether not to use CUDA when available',
    metavar=None)
  - _StoreAction(option_strings=['--top_k'], dest='top_k', nargs=None, const=None,
    default=256, type=<class 'int'>, choices=None, help=None, metavar=None)
  - _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=52313,
    type=<class 'int'>, choices=None, help='random seed for initialization', metavar=None)
  - _StoreAction(option_strings=['--zeshel'], dest='zeshel', nargs=None, const=None,
    default=True, type=<class 'bool'>, choices=None, help='Whether the dataset is
    from zeroshot.', metavar=None)
  - _StoreAction(option_strings=['--layers'], dest='layers', nargs=None, const=None,
    default=6, type=<class 'int'>, choices=None, help='number of layers for mlp structure',
    metavar=None)
  - _StoreTrueAction(option_strings=['--with_mlp'], dest='with_mlp', nargs=0, const=True,
    default=False, type=None, choices=None, help='Whether to add mlp layers on top
    of Bi-encoder.', metavar=None)
  - _StoreAction(option_strings=['--act_fn'], dest='act_fn', nargs=None, const=None,
    default='softplus', type=None, choices=None, help='softplus, sigmoid, tanh', metavar=None)
  - _StoreAction(option_strings=['--step_size'], dest='step_size', nargs=None, const=None,
    default=100, type=<class 'int'>, choices=None, help='number of layers for mlp
    structure', metavar=None)
  - _StoreAction(option_strings=['--max_seq_length'], dest='max_seq_length', nargs=None,
    const=None, default=256, type=<class 'int'>, choices=None, help='The maximum total
    input sequence length after WordPiece tokenization. \nSequences longer than this
    will be truncated, and sequences shorter \nthan this will be padded.', metavar=None)
  - _StoreAction(option_strings=['--max_context_length'], dest='max_context_length',
    nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='The
    maximum total context input sequence length after WordPiece tokenization. \nSequences
    longer than this will be truncated, and sequences shorter \nthan this will be
    padded.', metavar=None)
  - _StoreAction(option_strings=['--max_cand_length'], dest='max_cand_length', nargs=None,
    const=None, default=128, type=<class 'int'>, choices=None, help='The maximum total
    label input sequence length after WordPiece tokenization. \nSequences longer than
    this will be truncated, and sequences shorter \nthan this will be padded.', metavar=None)
  - _StoreAction(option_strings=['--path_to_model'], dest='path_to_model', nargs=None,
    const=None, default=None, type=<class 'str'>, choices=None, help='The full path
    to the model to load.', metavar=None)
  - '_StoreAction(option_strings=[''--bert_model''], dest=''bert_model'', nargs=None,
    const=None, default=''bert-base-cased'', type=<class ''str''>, choices=None, help=''Bert
    pre-trained model selected in the list: bert-base-uncased, bert-large-uncased,
    bert-base-cased, bert-base-multilingual, bert-base-chinese.'', metavar=None)'
  - _StoreAction(option_strings=['--architecture'], dest='architecture', nargs=None,
    const=None, default='mlp', type=<class 'str'>, choices=None, help='mlp, bert,
    roberta, special_token, raw_context_text', metavar=None)
  - _StoreAction(option_strings=['--pull_from_layer'], dest='pull_from_layer', nargs=None,
    const=None, default=-1, type=<class 'int'>, choices=None, help='Layers to pull
    from BERT', metavar=None)
  - _StoreFalseAction(option_strings=['--lowercase'], dest='lowercase', nargs=0, const=False,
    default=True, type=None, choices=None, help='Whether to lower case the input text.
    True for uncased models, False for cased models.', metavar=None)
  - _StoreAction(option_strings=['--context_key'], dest='context_key', nargs=None,
    const=None, default='context', type=<class 'str'>, choices=None, help=None, metavar=None)
  - _StoreAction(option_strings=['--out_dim'], dest='out_dim', nargs=None, const=None,
    default=1, type=<class 'int'>, choices=None, help='Output dimention of bi-encoders.',
    metavar=None)
  - _StoreAction(option_strings=['--add_linear'], dest='add_linear', nargs=None, const=None,
    default=False, type=<class 'bool'>, choices=None, help='Whether to add an additonal
    linear projection on top of BERT.', metavar=None)
  - _StoreAction(option_strings=['--data_path'], dest='data_path', nargs=None, const=None,
    default='models/zeshel/w_scores_256/top256_candidates/', type=<class 'str'>, choices=None,
    help='The path to the train data.', metavar=None)
  - _StoreAction(option_strings=['--output_path'], dest='output_path', nargs=None,
    const=None, default='models/zeshel/crossencoder/', type=<class 'str'>, choices=None,
    help='The output directory where generated output file (model, etc.) is to be
    dumped.', metavar=None)
  - _StoreAction(option_strings=['--wandb'], dest='wandb', nargs=None, const=None,
    default='BLINK-blink_crossencoder', type=<class 'str'>, choices=None, help='wandb
    project name.', metavar=None)
  - _StoreAction(option_strings=['--resume'], dest='resume', nargs=None, const=None,
    default=False, type=<class 'bool'>, choices=None, help='wandb project name.',
    metavar=None)
  - _StoreAction(option_strings=['--run_id'], dest='run_id', nargs=None, const=None,
    default='vas87n1', type=<class 'str'>, choices=None, help='wandb project name.',
    metavar=None)
  - _StoreAction(option_strings=['--without_64'], dest='without_64', nargs=None, const=None,
    default=True, type=<class 'bool'>, choices=None, help='to include 64 or not',
    metavar=None)
  - _StoreAction(option_strings=['--timeout'], dest='timeout', nargs=None, const=None,
    default=720, type=<class 'int'>, choices=None, help='timeout minutes.', metavar=None)
  - _StoreAction(option_strings=['--decoder'], dest='decoder', nargs=None, const=None,
    default=False, type=<class 'bool'>, choices=None, help='decoder strucutre or not.',
    metavar=None)
  - _StoreAction(option_strings=['--split'], dest='split', nargs=None, const=None,
    default=1, type=<class 'int'>, choices=None, help='split dataset into N chunks.
    (because of out of memory)', metavar=None)
  - _StoreTrueAction(option_strings=['--evaluate'], dest='evaluate', nargs=0, const=True,
    default=False, type=None, choices=None, help='Whether to run evaluation.', metavar=None)
  - _StoreAction(option_strings=['--scheduler_gamma'], dest='scheduler_gamma', nargs=None,
    const=None, default=0.9, type=<class 'float'>, choices=None, help='The txt file
    where the the evaluation results will be written.', metavar=None)
  - _StoreAction(option_strings=['--sampling'], dest='sampling', nargs=None, const=None,
    default=True, type=<class 'bool'>, choices=None, help='The txt file where the
    the evaluation results will be written.', metavar=None)
  - _StoreAction(option_strings=['--binary_loss'], dest='binary_loss', nargs=None,
    const=None, default=True, type=<class 'bool'>, choices=None, help='Binary cross
    entropy loss or multi class cross entropy loss.', metavar=None)
  - _StoreAction(option_strings=['--hard_negative'], dest='hard_negative', nargs=None,
    const=None, default=True, type=<class 'bool'>, choices=None, help='Random sampling
    or hard negative mining.', metavar=None)
  - _StoreAction(option_strings=['--weight_decay'], dest='weight_decay', nargs=None,
    const=None, default=0.9, type=<class 'float'>, choices=None, help='The txt file
    where the the evaluation results will be written.', metavar=None)
  - _StoreAction(option_strings=['--output_eval_file'], dest='output_eval_file', nargs=None,
    const=None, default=None, type=<class 'str'>, choices=None, help='The txt file
    where the the evaluation results will be written.', metavar=None)
  - _StoreAction(option_strings=['--train_batch_size'], dest='train_batch_size', nargs=None,
    const=None, default=128, type=<class 'int'>, choices=None, help='Total batch size
    for training.', metavar=None)
  - _StoreAction(option_strings=['--max_grad_norm'], dest='max_grad_norm', nargs=None,
    const=None, default=1.0, type=<class 'float'>, choices=None, help=None, metavar=None)
  - _StoreAction(option_strings=['--learning_rate'], dest='learning_rate', nargs=None,
    const=None, default=0.0001, type=<class 'float'>, choices=None, help='The initial
    learning rate for Adam.', metavar=None)
  - _StoreAction(option_strings=['--num_train_epochs'], dest='num_train_epochs', nargs=None,
    const=None, default=10000, type=<class 'int'>, choices=None, help='Number of training
    epochs.', metavar=None)
  - _StoreAction(option_strings=['--dim_red'], dest='dim_red', nargs=None, const=None,
    default=512, type=<class 'int'>, choices=None, help='first dimension', metavar=None)
  - _StoreAction(option_strings=['--train_size'], dest='train_size', nargs=None, const=None,
    default=-1, type=<class 'int'>, choices=None, help='dataset size of train set',
    metavar=None)
  - _StoreAction(option_strings=['--valid_size'], dest='valid_size', nargs=None, const=None,
    default=-1, type=<class 'int'>, choices=None, help='dataset size of dev set',
    metavar=None)
  - _StoreAction(option_strings=['--patience'], dest='patience', nargs=None, const=None,
    default=5, type=<class 'int'>, choices=None, help='patience for early stopping.',
    metavar=None)
  - _StoreAction(option_strings=['--print_interval'], dest='print_interval', nargs=None,
    const=None, default=50, type=<class 'int'>, choices=None, help='Interval of loss
    printing', metavar=None)
  - _StoreAction(option_strings=['--eval_interval'], dest='eval_interval', nargs=None,
    const=None, default=200, type=<class 'int'>, choices=None, help='Interval for
    evaluation during training', metavar=None)
  - _StoreAction(option_strings=['--save_interval'], dest='save_interval', nargs=None,
    const=None, default=1, type=<class 'int'>, choices=None, help='Interval for model
    saving', metavar=None)
  - _StoreAction(option_strings=['--warmup_proportion'], dest='warmup_proportion',
    nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='Proportion
    of training to perform linear learning rate warmup for. E.g., 0.1 = 10% of training.',
    metavar=None)
  - _StoreAction(option_strings=['--gradient_accumulation_steps'], dest='gradient_accumulation_steps',
    nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Number
    of updates steps to accumualte before performing a backward/update pass.', metavar=None)
  - _StoreAction(option_strings=['--type_optimization'], dest='type_optimization',
    nargs=None, const=None, default='all_encoder_layers', type=<class 'str'>, choices=None,
    help='Which type of layers to optimize in BERT', metavar=None)
  - _StoreAction(option_strings=['--shuffle'], dest='shuffle', nargs=None, const=None,
    default=False, type=<class 'bool'>, choices=None, help='Whether to shuffle train
    data', metavar=None)
  - _StoreAction(option_strings=['--save'], dest='save', nargs=None, const=None, default=True,
    type=<class 'bool'>, choices=None, help='directory to save models', metavar=None)
  - _StoreAction(option_strings=['--dim'], dest='dim', nargs=None, const=None, default=1024,
    type=<class 'int'>, choices=None, help=None, metavar=None)
  - _StoreAction(option_strings=['--optimizer'], dest='optimizer', nargs=None, const=None,
    default='AdamW', type=<class 'str'>, choices=None, help='optimizer.', metavar=None)
  - _StoreAction(option_strings=['--eval_batch_size'], dest='eval_batch_size', nargs=None,
    const=None, default=128, type=<class 'int'>, choices=None, help='Total batch size
    for evaluation.', metavar=None)
  - _StoreAction(option_strings=['--mode'], dest='mode', nargs=None, const=None, default='valid',
    type=<class 'str'>, choices=None, help='Train / validation / test', metavar=None)
  - _StoreTrueAction(option_strings=['--save_topk_result'], dest='save_topk_result',
    nargs=0, const=True, default=False, type=None, choices=None, help='Whether to
    save prediction results.', metavar=None)
  - _StoreAction(option_strings=['--encode_batch_size'], dest='encode_batch_size',
    nargs=None, const=None, default=8, type=<class 'int'>, choices=None, help='Batch
    size for encoding.', metavar=None)
  - _StoreAction(option_strings=['--cand_pool_path'], dest='cand_pool_path', nargs=None,
    const=None, default=None, type=<class 'str'>, choices=None, help='Path for cached
    candidate pool (id tokenization of candidates)', metavar=None)
  - _StoreAction(option_strings=['--cand_encode_path'], dest='cand_encode_path', nargs=None,
    const=None, default=None, type=<class 'str'>, choices=None, help='Path for cached
    candidate encoding', metavar=None)
  - _StoreAction(option_strings=['--cand_cls_path'], dest='cand_cls_path', nargs=None,
    const=None, default=None, type=<class 'str'>, choices=None, help='Path for cached
    candidate cls encoding', metavar=None)
_defaults:
  desc: null
  value: {}
_has_negative_number_optionals:
  desc: null
  value: []
_mutually_exclusive_groups:
  desc: null
  value: []
_negative_number_matcher:
  desc: null
  value: re.compile('^-\\d+$|^-\\d*\\.\\d+$')
_option_string_actions:
  desc: null
  value:
    --act_fn: _StoreAction(option_strings=['--act_fn'], dest='act_fn', nargs=None,
      const=None, default='softplus', type=None, choices=None, help='softplus, sigmoid,
      tanh', metavar=None)
    --add_linear: _StoreAction(option_strings=['--add_linear'], dest='add_linear',
      nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, help='Whether
      to add an additonal linear projection on top of BERT.', metavar=None)
    --architecture: _StoreAction(option_strings=['--architecture'], dest='architecture',
      nargs=None, const=None, default='mlp', type=<class 'str'>, choices=None, help='mlp,
      bert, roberta, special_token, raw_context_text', metavar=None)
    --bert_model: '_StoreAction(option_strings=[''--bert_model''], dest=''bert_model'',
      nargs=None, const=None, default=''bert-base-cased'', type=<class ''str''>, choices=None,
      help=''Bert pre-trained model selected in the list: bert-base-uncased, bert-large-uncased,
      bert-base-cased, bert-base-multilingual, bert-base-chinese.'', metavar=None)'
    --binary_loss: _StoreAction(option_strings=['--binary_loss'], dest='binary_loss',
      nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, help='Binary
      cross entropy loss or multi class cross entropy loss.', metavar=None)
    --cand_cls_path: _StoreAction(option_strings=['--cand_cls_path'], dest='cand_cls_path',
      nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Path
      for cached candidate cls encoding', metavar=None)
    --cand_encode_path: _StoreAction(option_strings=['--cand_encode_path'], dest='cand_encode_path',
      nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Path
      for cached candidate encoding', metavar=None)
    --cand_pool_path: _StoreAction(option_strings=['--cand_pool_path'], dest='cand_pool_path',
      nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Path
      for cached candidate pool (id tokenization of candidates)', metavar=None)
    --context_key: _StoreAction(option_strings=['--context_key'], dest='context_key',
      nargs=None, const=None, default='context', type=<class 'str'>, choices=None,
      help=None, metavar=None)
    --data_parallel: _StoreAction(option_strings=['--data_parallel'], dest='data_parallel',
      nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, help='Whether
      to distributed the candidate generation process.', metavar=None)
    --data_path: _StoreAction(option_strings=['--data_path'], dest='data_path', nargs=None,
      const=None, default='models/zeshel/w_scores_256/top256_candidates/', type=<class
      'str'>, choices=None, help='The path to the train data.', metavar=None)
    --debug: _StoreTrueAction(option_strings=['--debug'], dest='debug', nargs=0, const=True,
      default=False, type=None, choices=None, help='Whether to run in debug mode with
      only 200 samples.', metavar=None)
    --decoder: _StoreAction(option_strings=['--decoder'], dest='decoder', nargs=None,
      const=None, default=False, type=<class 'bool'>, choices=None, help='decoder
      strucutre or not.', metavar=None)
    --dim: _StoreAction(option_strings=['--dim'], dest='dim', nargs=None, const=None,
      default=1024, type=<class 'int'>, choices=None, help=None, metavar=None)
    --dim_red: _StoreAction(option_strings=['--dim_red'], dest='dim_red', nargs=None,
      const=None, default=512, type=<class 'int'>, choices=None, help='first dimension',
      metavar=None)
    --encode_batch_size: _StoreAction(option_strings=['--encode_batch_size'], dest='encode_batch_size',
      nargs=None, const=None, default=8, type=<class 'int'>, choices=None, help='Batch
      size for encoding.', metavar=None)
    --eval_batch_size: _StoreAction(option_strings=['--eval_batch_size'], dest='eval_batch_size',
      nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='Total
      batch size for evaluation.', metavar=None)
    --eval_interval: _StoreAction(option_strings=['--eval_interval'], dest='eval_interval',
      nargs=None, const=None, default=200, type=<class 'int'>, choices=None, help='Interval
      for evaluation during training', metavar=None)
    --evaluate: _StoreTrueAction(option_strings=['--evaluate'], dest='evaluate', nargs=0,
      const=True, default=False, type=None, choices=None, help='Whether to run evaluation.',
      metavar=None)
    --gradient_accumulation_steps: _StoreAction(option_strings=['--gradient_accumulation_steps'],
      dest='gradient_accumulation_steps', nargs=None, const=None, default=1, type=<class
      'int'>, choices=None, help='Number of updates steps to accumualte before performing
      a backward/update pass.', metavar=None)
    --hard_negative: _StoreAction(option_strings=['--hard_negative'], dest='hard_negative',
      nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, help='Random
      sampling or hard negative mining.', metavar=None)
    --help: _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None,
      default='==SUPPRESS==', type=None, choices=None, help='show this help message
      and exit', metavar=None)
    --layers: _StoreAction(option_strings=['--layers'], dest='layers', nargs=None,
      const=None, default=6, type=<class 'int'>, choices=None, help='number of layers
      for mlp structure', metavar=None)
    --learning_rate: _StoreAction(option_strings=['--learning_rate'], dest='learning_rate',
      nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None,
      help='The initial learning rate for Adam.', metavar=None)
    --lowercase: _StoreFalseAction(option_strings=['--lowercase'], dest='lowercase',
      nargs=0, const=False, default=True, type=None, choices=None, help='Whether to
      lower case the input text. True for uncased models, False for cased models.',
      metavar=None)
    --max_cand_length: _StoreAction(option_strings=['--max_cand_length'], dest='max_cand_length',
      nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='The
      maximum total label input sequence length after WordPiece tokenization. \nSequences
      longer than this will be truncated, and sequences shorter \nthan this will be
      padded.', metavar=None)
    --max_context_length: _StoreAction(option_strings=['--max_context_length'], dest='max_context_length',
      nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='The
      maximum total context input sequence length after WordPiece tokenization. \nSequences
      longer than this will be truncated, and sequences shorter \nthan this will be
      padded.', metavar=None)
    --max_grad_norm: _StoreAction(option_strings=['--max_grad_norm'], dest='max_grad_norm',
      nargs=None, const=None, default=1.0, type=<class 'float'>, choices=None, help=None,
      metavar=None)
    --max_seq_length: _StoreAction(option_strings=['--max_seq_length'], dest='max_seq_length',
      nargs=None, const=None, default=256, type=<class 'int'>, choices=None, help='The
      maximum total input sequence length after WordPiece tokenization. \nSequences
      longer than this will be truncated, and sequences shorter \nthan this will be
      padded.', metavar=None)
    --mode: _StoreAction(option_strings=['--mode'], dest='mode', nargs=None, const=None,
      default='valid', type=<class 'str'>, choices=None, help='Train / validation
      / test', metavar=None)
    --no_cuda: _StoreTrueAction(option_strings=['--no_cuda'], dest='no_cuda', nargs=0,
      const=True, default=False, type=None, choices=None, help='Whether not to use
      CUDA when available', metavar=None)
    --num_train_epochs: _StoreAction(option_strings=['--num_train_epochs'], dest='num_train_epochs',
      nargs=None, const=None, default=10000, type=<class 'int'>, choices=None, help='Number
      of training epochs.', metavar=None)
    --optimizer: _StoreAction(option_strings=['--optimizer'], dest='optimizer', nargs=None,
      const=None, default='AdamW', type=<class 'str'>, choices=None, help='optimizer.',
      metavar=None)
    --out_dim: _StoreAction(option_strings=['--out_dim'], dest='out_dim', nargs=None,
      const=None, default=1, type=<class 'int'>, choices=None, help='Output dimention
      of bi-encoders.', metavar=None)
    --output_eval_file: _StoreAction(option_strings=['--output_eval_file'], dest='output_eval_file',
      nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The
      txt file where the the evaluation results will be written.', metavar=None)
    --output_path: _StoreAction(option_strings=['--output_path'], dest='output_path',
      nargs=None, const=None, default='models/zeshel/crossencoder/', type=<class 'str'>,
      choices=None, help='The output directory where generated output file (model,
      etc.) is to be dumped.', metavar=None)
    --path_to_model: _StoreAction(option_strings=['--path_to_model'], dest='path_to_model',
      nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The
      full path to the model to load.', metavar=None)
    --patience: _StoreAction(option_strings=['--patience'], dest='patience', nargs=None,
      const=None, default=5, type=<class 'int'>, choices=None, help='patience for
      early stopping.', metavar=None)
    --print_interval: _StoreAction(option_strings=['--print_interval'], dest='print_interval',
      nargs=None, const=None, default=50, type=<class 'int'>, choices=None, help='Interval
      of loss printing', metavar=None)
    --pull_from_layer: _StoreAction(option_strings=['--pull_from_layer'], dest='pull_from_layer',
      nargs=None, const=None, default=-1, type=<class 'int'>, choices=None, help='Layers
      to pull from BERT', metavar=None)
    --resume: _StoreAction(option_strings=['--resume'], dest='resume', nargs=None,
      const=None, default=False, type=<class 'bool'>, choices=None, help='wandb project
      name.', metavar=None)
    --run_id: _StoreAction(option_strings=['--run_id'], dest='run_id', nargs=None,
      const=None, default='vas87n1', type=<class 'str'>, choices=None, help='wandb
      project name.', metavar=None)
    --sampling: _StoreAction(option_strings=['--sampling'], dest='sampling', nargs=None,
      const=None, default=True, type=<class 'bool'>, choices=None, help='The txt file
      where the the evaluation results will be written.', metavar=None)
    --save: _StoreAction(option_strings=['--save'], dest='save', nargs=None, const=None,
      default=True, type=<class 'bool'>, choices=None, help='directory to save models',
      metavar=None)
    --save_interval: _StoreAction(option_strings=['--save_interval'], dest='save_interval',
      nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Interval
      for model saving', metavar=None)
    --save_topk_result: _StoreTrueAction(option_strings=['--save_topk_result'], dest='save_topk_result',
      nargs=0, const=True, default=False, type=None, choices=None, help='Whether to
      save prediction results.', metavar=None)
    --scheduler_gamma: _StoreAction(option_strings=['--scheduler_gamma'], dest='scheduler_gamma',
      nargs=None, const=None, default=0.9, type=<class 'float'>, choices=None, help='The
      txt file where the the evaluation results will be written.', metavar=None)
    --seed: _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None,
      default=52313, type=<class 'int'>, choices=None, help='random seed for initialization',
      metavar=None)
    --shuffle: _StoreAction(option_strings=['--shuffle'], dest='shuffle', nargs=None,
      const=None, default=False, type=<class 'bool'>, choices=None, help='Whether
      to shuffle train data', metavar=None)
    --silent: _StoreTrueAction(option_strings=['--silent'], dest='silent', nargs=0,
      const=True, default=False, type=None, choices=None, help='Whether to print progress
      bars.', metavar=None)
    --split: _StoreAction(option_strings=['--split'], dest='split', nargs=None, const=None,
      default=1, type=<class 'int'>, choices=None, help='split dataset into N chunks.
      (because of out of memory)', metavar=None)
    --step_size: _StoreAction(option_strings=['--step_size'], dest='step_size', nargs=None,
      const=None, default=100, type=<class 'int'>, choices=None, help='number of layers
      for mlp structure', metavar=None)
    --timeout: _StoreAction(option_strings=['--timeout'], dest='timeout', nargs=None,
      const=None, default=720, type=<class 'int'>, choices=None, help='timeout minutes.',
      metavar=None)
    --top_k: _StoreAction(option_strings=['--top_k'], dest='top_k', nargs=None, const=None,
      default=256, type=<class 'int'>, choices=None, help=None, metavar=None)
    --train_batch_size: _StoreAction(option_strings=['--train_batch_size'], dest='train_batch_size',
      nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='Total
      batch size for training.', metavar=None)
    --train_size: _StoreAction(option_strings=['--train_size'], dest='train_size',
      nargs=None, const=None, default=-1, type=<class 'int'>, choices=None, help='dataset
      size of train set', metavar=None)
    --type_optimization: _StoreAction(option_strings=['--type_optimization'], dest='type_optimization',
      nargs=None, const=None, default='all_encoder_layers', type=<class 'str'>, choices=None,
      help='Which type of layers to optimize in BERT', metavar=None)
    --valid_size: _StoreAction(option_strings=['--valid_size'], dest='valid_size',
      nargs=None, const=None, default=-1, type=<class 'int'>, choices=None, help='dataset
      size of dev set', metavar=None)
    --wandb: _StoreAction(option_strings=['--wandb'], dest='wandb', nargs=None, const=None,
      default='BLINK-blink_crossencoder', type=<class 'str'>, choices=None, help='wandb
      project name.', metavar=None)
    --warmup_proportion: _StoreAction(option_strings=['--warmup_proportion'], dest='warmup_proportion',
      nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='Proportion
      of training to perform linear learning rate warmup for. E.g., 0.1 = 10% of training.',
      metavar=None)
    --weight_decay: _StoreAction(option_strings=['--weight_decay'], dest='weight_decay',
      nargs=None, const=None, default=0.9, type=<class 'float'>, choices=None, help='The
      txt file where the the evaluation results will be written.', metavar=None)
    --with_mlp: _StoreTrueAction(option_strings=['--with_mlp'], dest='with_mlp', nargs=0,
      const=True, default=False, type=None, choices=None, help='Whether to add mlp
      layers on top of Bi-encoder.', metavar=None)
    --without_64: _StoreAction(option_strings=['--without_64'], dest='without_64',
      nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, help='to
      include 64 or not', metavar=None)
    --zeshel: _StoreAction(option_strings=['--zeshel'], dest='zeshel', nargs=None,
      const=None, default=True, type=<class 'bool'>, choices=None, help='Whether the
      dataset is from zeroshot.', metavar=None)
    -h: _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None,
      default='==SUPPRESS==', type=None, choices=None, help='show this help message
      and exit', metavar=None)
_optionals:
  desc: null
  value: <argparse._ArgumentGroup object at 0x7fac3c462810>
_positionals:
  desc: null
  value: <argparse._ArgumentGroup object at 0x7fac3b6cf4d0>
_registries:
  desc: null
  value:
    action:
      append: argparse._AppendAction
      append_const: argparse._AppendConstAction
      count: argparse._CountAction
      help: argparse._HelpAction
      'null': argparse._StoreAction
      parsers: argparse._SubParsersAction
      store: argparse._StoreAction
      store_const: argparse._StoreConstAction
      store_false: argparse._StoreFalseAction
      store_true: argparse._StoreTrueAction
      version: argparse._VersionAction
    type:
      'null': argparse.ArgumentParser.__init__.<locals>.identity
_subparsers:
  desc: null
  value: null
_wandb:
  desc: null
  value:
    cli_version: 0.13.10
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.12
    start_time: 1677082015.570859
    t:
      1:
      - 1
      - 53
      - 55
      2:
      - 1
      - 53
      - 55
      3:
      - 16
      - 23
      4: 3.7.12
      5: 0.13.10
      8:
      - 5
add_arg:
  desc: null
  value: argparse._ActionsContainer.add_argument
add_help:
  desc: null
  value: true
allow_abbrev:
  desc: null
  value: false
argument_default:
  desc: null
  value: null
blink_home:
  desc: null
  value: /home/jongsong/BLINK
conflict_handler:
  desc: null
  value: resolve
description:
  desc: null
  value: BLINK parser
epilog:
  desc: null
  value: null
formatter_class:
  desc: null
  value: argparse.HelpFormatter
fromfile_prefix_chars:
  desc: null
  value: null
overridable:
  desc: null
  value: {}
prefix_chars:
  desc: null
  value: '-'
prog:
  desc: null
  value: train_cross.py
usage:
  desc: null
  value: null
